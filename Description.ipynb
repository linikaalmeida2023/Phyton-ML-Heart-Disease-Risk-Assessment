{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "452b2648",
   "metadata": {},
   "source": [
    "# CA1 Data Preparation\n",
    "\n",
    "### Student - Linika Almeida, ID - 2023045\n",
    "### Lais Ameno, ID - 2023101\n",
    "### Eduardo , ID - 2023077"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507fe6df",
   "metadata": {},
   "source": [
    "### DESCRIPTION \n",
    "\n",
    "The dataset was collected in the kaggle website.\n",
    "This data provides information about people who have or not had a heart stroke and some information about risk factors that may contribute to this disease.\n",
    "Using the information at hand, we attempt to comprehend how various clinical characteristics and risk factors affect the incidence of heart attacks. Clinical characteristics and risk factors include diabetes prevalence, gender, age, cholesterol, glucose, BMI, and smoking frequency.\n",
    "\n",
    "##### Main Goal\n",
    "Improve health outcomes and reduce health care coast for the company and prevent any eventual dispends with patients that have heart disease conditions.\n",
    "______________________\n",
    "For this purpose we are going to apply three different classification models: KNN, SVM, Random Forest. This coice was made due:\n",
    "* KNN - Due to its ability to cluster similar data together, is able to recognize patterns in data pertaining to risk factors that result in strokes. It can demonstrate how clients with risk indicators are similar to one another and assist in locating comparable clients, allowing insurance plans to be customized.\n",
    "\n",
    "* SVM - divides clients into distinct risk classes in a linear fashion according to risk variables. Additionally, it clearly delineates the limit between clients at high and low risk.\n",
    "\n",
    "* Random Forest - is capable of deciphering intricate patterns and recognizing clients with peculiar traits that might pose an uncommon risk. able to identify the traits that are most important in predicting the likelihood of a stroke and aids in determining the overall risk connected to various client profiles.\n",
    "\n",
    "#### The meaning of each column in the data is as below\n",
    "\n",
    "    1. Gender: The gender of the patient\n",
    "    2. Age: The age of the patient\n",
    "    3. Education: The studies of the patient\n",
    "    4. currentSmoker: The patient is a current smoker? (No = 0, Yes = 1)\n",
    "    5. cigsPerDay: Quantity of cigarretes that the patient smokes each day\n",
    "    6. BPMeds: The patient use blood pressure medication? (No = 0, Yes = 1)\n",
    "    7. prevalentStroke: The patient had a stroke recently? (No = 0, Yes = 1)\n",
    "    8. prevalentHyp: The patient had hypertension problems recently? (No = 0, Yes = 1)\n",
    "    9. diabetes: The patient have diabetes? (No = 0, Yes = 1)\n",
    "    10. totChol: Total of cholesterol of the patient\n",
    "    11. sysBP: Systolic blood pressure of the patient\n",
    "    12. diaBP: Diastolic blood pressure of the patient\n",
    "    13. BMI: Body mass index of the patient\n",
    "    14. heartRate: Heart rate of the patient\n",
    "    15. glucose: Glucose of patient\n",
    "    16. Heart_stroke: The patient will have a heart_stroke? (No = 0, Yes = 1)\n",
    "    \n",
    "  ##### * Target Variable: heart_stroke\n",
    "___\n",
    "    \n",
    "Github Repository:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedaf1dc",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93777d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "#https://github.com/parrt/dtreeviz/blob/master/notebooks/dtreeviz_sklearn_visualisations.ipynb\n",
    "import dtreeviz\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "#Libraries for Saving the Model\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from yellowbrick.classifier import (ConfusionMatrix, ROCAUC, ClassificationReport,\n",
    "ClassPredictionError, ClassBalance)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set() \n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV \n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19e8c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "df = pd.read_csv(\"heart_disease.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51a33deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U imbalanced-learn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
